from huggingface_hub import InferenceClient
from huggingface_hub import login
from huggingface_hub import InferenceClient
import json

login(token="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")

strr = " I don't know if you know this, but there's an entire industry in India built to help young Indians crack the fang into you. How do you get out of the competitive exam mindset with all these shifts coming about? I think real success comes from understanding things in a deeper way. Almost tempted to go back to the movie Three Idiots or something like that. And like, you know, there's a scene in there when they ask Amir Khan the definition of a motor. And like, you know, there's a version you just describe what a motor is. And there's a version where you actually understand what a motor is. I come from India and I feel like this is an AI race and Silicon Valley is like moving really fast. We're sort of getting left behind. If you were an engineer back home in India, what would you do to keep up? I see it a bit differently. For us now, India is one of our top markets. It's our largest user base. The underlying API for AI are available everywhere, including India. So I see developers already using it. So Google got into a little bit of trouble recently with generating historical characters with some racial inaccuracies. I want to ask you a slightly more personal question. Food in India.  Here's how you can make these cool AI videos in which the camera seems to float through an image. It's wild. We're basically teaching computers to dream up parts of photos we never captured. First, upload your image to Runway. They have launched a new feature called Camera Control, where you will make multiple videos moving in different directions. Let's break it down. Number one, make your first video moving forward. Number two, make another one moving backward from a different angle. And lastly, create a few more with different movements, maybe panning left or right. What's happening behind the scenes is fascinating. The AI creates what we call a depth map, basically figuring out what's close to the camera and what's far away. Finally, here's where the magic happens. We're heading into After Effects, where first you drop your video onto a new composition, Then go to the timeline and hit time remapping and lastly add keyframes to control the speed. That's it. After playing around with a few keyframes and putting them all together, you get this endless smooth loop that looks absolutely incredible.  Let's say if somebody was 18, 19 years old, probably studying computer science, what would your advice to them be? The only sustainable technology advantage is find something that's really, really hard to do and get really, really good at it, right? Really learning what your passion is, what drives you, and making the time to get really good at it. And then you can figure out what it applies to. One thing I will say is learning how to learn is the key. And when I look back, the specific systems and techniques I'm working on, But knowing how systems work, knowing the underlying dynamics of how to build good systems, of how to find market and product fit, those things never change. As a CTO, you became a human behavioral expert. Absolutely. And I think human-computer interactions is one of the richest fields of study we have right now. All you have are the people who show up every day trying to make something happen. And even when you're at a MasterCard, you recognize it's just 60 years of people bringing their best work, bringing their thoughts, and building that value. I  For over 60 years, scientists have taught apes to use sign language to communicate. But in all that time, across all those studies, no ape has ever asked a single question. Not one. It turns out that asking questions requires something special. Understanding that there are things you don't know that someone else might know. Scientists call this metacognition. Basically, thinking about thinking. Despite being incredibly intelligent in many ways, apes don't have this capability. They can't imagine information existing in someone else's head that isn't in their own. And this isn't just about apes. Look at our world today. So many conflicts over religion, nationality and identity happen because people can't imagine that others might see the world differently than they do. It's like they're stuck in their own mental model. And that's actually a sign of limited cognitive ability, just like those apes who can't ask questions. But this understanding of different mental models is so fundamental to intelligence that we've actually built it into AI. When ChatGPT asks for clarification or more context, it's demonstrating something our closest animal relatives can't do. recognizing gaps in its knowledge and understanding that others might have different information. This changes how we think about intelligence, learning and even consciousness.  What are you excited about in 2025? What's to come? AGI? Yeah. Excited for that. Here are top three future predictions from Sam Altman's recent YC interview. Have companies that make, you know, billions of dollars per year and have like less than 100 employees, maybe 50, maybe 20 employees, maybe one. I don't know what to make of that other than it's a great time to be a startup founder. Yeah. You know, it's like one person plus 10,000 GPUs. ASI, superintelligence, is actually thousands of days away. Maybe. I mean, that's our hope, our guess, whatever. But that's a very wild statement. Yeah. I can see a path where the work we are doing just keeps compounding. And over the last three years, continues for the next three or six or nine or whatever. You know, nine years will be like 3,500 days or whatever. If we can keep this rate of improvement or even increase it, that system will be quite capable of doing a lot of things. Our research path is fairly clear, our infrastructure path is fairly clear, our product path is getting clearer. I had been telling people for a while, I thought that level 2 to level 3 was going to happen quickly. And then the level 3 to level 4 jump was somehow going to be much harder and require some medium-sized or larger new ideas. And that demo and a few others have convinced me that you can get a huge amount of innovation just by using these current models in really creative ways.  Elon Musk and Mukesh Ambani are fighting over India's internet and Musk may have just won. Here's what's happening. Elon's Starlink has this massive network of 6,400 satellites orbiting Earth, beaming high-speed internet to even the most remote places. But when Starlink wanted to bring this tech to India, Mukesh Ambani, who spent $19 billion building traditional networks, wasn't happy. Reuters reports Reliance wanted Starlink to auction billions just to enter India by bidding for satellite spectrum. Basically, the signal satellites use to beam internet from space. That's completely unusual because these satellite signals are coordinated globally by the UN, not sold by individual countries. After all, satellites orbit the whole Earth. Now, to all this, Musk just tweeted unprecedented and said he'd call Ambani to ask if it wouldn't be too much trouble to let Starlink compete. But just recently, the Indian government made its decision. It sided with Musk. It's sticking to global practices, which means Starlink can now offer unlimited data plans way cheaper than what's out there. So while the billionaire drama is fun, the real win here is for millions of Indians who finally get online plus everyone else will get cheaper internet net  There's going to be a point in the future where these AI agents go out and make money by themselves. Just take a moment to think about how crazy it is that you can ask that question. Mustafa Suleiman, the CEO of Microsoft AI, founder of DeepMind, one of the OGs of the AI world. With a decade at the forefront of this industry. If anyone can go out there and just say, hey, spin me software that does ABCD, what happens to the entire field of software as a service? Instead of just a computer being able to say things, it will actually be able to do things. It'll take actions. It'll learn to use APIs. It'll buy things. It'll write emails. It'll make phone calls, just as an entrepreneur would.  This company is selling sunlight by putting mirrors in space. Here's how it works. You open their app at night, select your location and tap a button. The app communicates with their satellite network, which then adjusts one or more orbiting mirrors to direct a beam of sunlight to your exact position. Now, the startup is called Reflect Orbital, and their idea is simple. Put a bunch of giant mirrors in space. During the day, these mirrors reflect sunlight to solar farms on Earth, allowing them to generate power even after sunset. At night, the mirrors can beam focused light to specific spots on the ground. But if you can call down light at will, people are definitely going to use it to advertise. Imagine looking up at night and seeing a giant silhouette in the sky like a high-tech bat signal, but for, I don't know, fast food maybe. It's like having a massive celestial billboard that can appear anywhere, anytime. And eventually, they might even be able to beam ads right in front of your feet as you walk.  AI just learned how to smell. Scientists have finally cracked the code on digitizing scent, starting with a fresh summer plum. But how do you teach a computer to understand something as complex as smell? See, when you smell something, you're actually detecting molecules floating through the air and binding to receptors in your nose. Those receptors then send signals to your brain that says, Plum! But capturing and recreating those exact molecules, that's way harder than it sounds. So here's what the team did. First, they trapped the scent molecules from a freshly cut plum in this special vial. Then, they used AI to analyze and identify the exact molecular structure of those scent compounds. Think of it as teaching a computer to take a really detailed photograph, but instead of light, it captures chemical signatures. The real breakthrough came next. The AI used that molecular photograph as a recipe to recreate the exact same compounds from scratch. The result was mind-blowing when they printed these synthetic molecules. It smelled exactly like the original plum. This technology could help us detect diseases, find dangerous gases, or even preserve experiences in entirely new ways. Imagine being able to share not just the sights and sounds of a moment, but also the smells.  ChatGPT just got a massive upgrade. It can finally search the internet. Watch this. Can you explain a few top Indian stocks that declined this week and what it means for those industries? Now, as you can see, it can blend real-time stock data with more deeper analysis, pulling insights from multiple news sources to give you the full picture. This is wild because before ChatGPT was stuck in 2022, it couldn't tell you anything current. And instead of bouncing between a browser and GPT, this time everything's right here. Plus, you can see where it's getting its information from. See this little sources button? It shows you exactly which websites and articles it used. However, interestingly, you won't find any New York Times articles since they're suing OpenAI instead of partnering with them. Now, ChatGPT Search uses a fine-tuned version of GPT-4.0, post-trained using novel synthetic data generation techniques. Although I love how this could change how we search for information, it's still in its early stages and it can sometimes mix up facts. For example, yesterday, someone used it to search about GPT-5 and it completely made up a fake launch event in London. So, while it's amazing for research and quick answers, always double check important stuff.  Have you wondered why so many games these days require you to go through a narrow passage? Well, there's a reason for it. It's actually a cleverly disguised loading screen where you feel like you still have control. In older games, you'd see an obvious loading screen when your character needed to move to a new area. But game developers realized that broke the immersion. So they came up with this brilliant trick, making you squeeze through a tight gap or climb through a narrow tunnel while the next area loads in the background. It's pretty genius when you think about it. While you're slowly moving your character through that tight space, the game is busy loading all the textures, models and effects for the next area. But instead of staring at a static screen, you feel like you're still playing. The tech behind this has also gotten really creative. Some games use elevator rides and others use long rope climbs. The key is keeping you occupied just long enough for everything to load. But gamers are starting to get tired of these sequences. And I get it. Once you know what they are, you start seeing them everywhere. And some players are saying, just give us a loading screen. But with gaming hardware getting better, by the day we might be seeing less of these sequences anyway. Though honestly, I love how this shows us something fascinating about game design.."

pp = "Using the style of Karan, generate a detailed and insightful description about the AI revolution. Focus on its impact, challenges, and future potential, while maintaining a conversational tone."

def generate_costum_dis(script,prompt):
    given_review = script
    given_prompt = f'{prompt}{given_review}'

    generator = InferenceClient(model='meta-llama/Llama-3.2-3B-Instruct' , timeout=120)

    generated_respo = generator.post(
        json={
            'inputs' : given_prompt,
            'parameters':{'max_new_tokens' : 200},
            'task' : 'text-generation'
        }
    )

    res = json.loads(generated_respo.decode())[0]["generated_text"]
    res = res[len(prompt):]
    res = res[len(script):]

    print("ðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µ")
    print(f"{res}")
    print("ðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µðŸ”µ")

    return res


generate_costum_dis(strr,pp)
